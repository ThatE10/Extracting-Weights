{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CSc2puvELNbs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List, Callable\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "m=20\n",
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ooc50RQiLSxs"
   },
   "outputs": [],
   "source": [
    "W=torch.rand((m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k6pGqYscLjz4"
   },
   "outputs": [],
   "source": [
    "relu=torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uyn5NvC9Lo5P"
   },
   "outputs": [],
   "source": [
    "z=torch.rand((n))\n",
    "b=torch.rand((n))\n",
    "c=torch.rand((m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43GOTM33Lv6j",
    "outputId": "8caf1f51-6bc3-48e2-94d5-9f09eadd2cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7856, 5.1820, 3.8472, 6.0928, 7.6088, 5.9614, 7.5286, 6.7736, 5.4397,\n",
       "        6.3900, 7.0223, 6.1708, 6.6048, 4.7607, 4.6629, 6.8944, 5.9208, 3.9657,\n",
       "        7.8036, 7.6734])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W@relu(z+b)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi4qQAgnMIyJ",
    "outputId": "8d973635-2d19-4199-c3aa-3c0cd9dc6ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: 2.0\n",
      "First derivative: 1.0\n",
      "Second derivative: 0.0\n",
      "Third derivative: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)  # Pick x > 0 to avoid the ReLU non-smooth point\n",
    "f = torch.relu(x)\n",
    "\n",
    "# First derivative\n",
    "df_dx = torch.autograd.grad(f, x, grad_outputs=torch.ones_like(f),create_graph=True)[0]\n",
    "\n",
    "# Second derivative\n",
    "d2f_dx2 = torch.autograd.grad(df_dx, x, grad_outputs=torch.ones_like(f),create_graph=True)[0]\n",
    "\n",
    "# Third derivative\n",
    "d3f_dx3 = torch.autograd.grad(d2f_dx2, x, grad_outputs=torch.ones_like(f),create_graph=True)[0]\n",
    "\n",
    "print(\"f:\", f.item())\n",
    "print(\"First derivative:\", df_dx.item())\n",
    "print(\"Second derivative:\", d2f_dx2.item())\n",
    "print(\"Third derivative:\", d3f_dx3.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8ebEb2A4N31q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wR0dgfaOtb2v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LlamaMLP(nn.Module):\n",
    "    def __init__(self, hidden_size=4096, intermediate_size=11008):\n",
    "        super().__init__()\n",
    "        self.gate_proj = nn.Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.up_proj = nn.Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(intermediate_size, hidden_size, bias=False)\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_gate = self.activation(self.gate_proj(x))       # [B, I]\n",
    "        x_up = self.up_proj(x)            # [B, I]\n",
    "        x_inner_prod =  x_gate * x_up  # [B, I]\n",
    "        output = self.down_proj(x_inner_prod)          # [B, H]\n",
    "        return output\n",
    "\n",
    "    def call(self,x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvLEH4sSn3k-",
    "outputId": "e0f9d7f0-936b-4bfb-aba5-4b2ee0aba83f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_matrix_difference (__main__.TestMatrixDifference.test_matrix_difference) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import torch\n",
    "\n",
    "class TestMatrixDifference(unittest.TestCase):\n",
    "    def test_matrix_difference(self):\n",
    "        # Example matrices\n",
    "        A = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "        B = torch.tensor([[1.0, 2.0001], [3.0, 4.0]])\n",
    "\n",
    "        # Using torch.testing.assert_close for detailed comparison\n",
    "        torch.testing.assert_close(A, B, rtol=1e-3, atol=1e-4)\n",
    "\n",
    "# Run the tests in the notebook\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestMatrixDifference)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "runner.run(suite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_obhnnkhzpCp"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p6pUtp4yv46k"
   },
   "outputs": [],
   "source": [
    "def taylor_series_components(\n",
    "    W: Tensor,\n",
    "    b: Tensor,\n",
    "    c: Tensor,\n",
    "    f: Callable[[Tensor], Tensor],\n",
    "    iters: int = 10\n",
    ") -> Tuple[List[Tensor], Tensor]:\n",
    "    \"\"\"\n",
    "    Compute components for a Taylor series expansion with a neural activation.\n",
    "\n",
    "    Args:\n",
    "        W (Tensor): Weight matrix of shape (m, n).\n",
    "        b (Tensor): Bias vector of shape (n,).\n",
    "        c (Tensor): Coefficient vector of shape (m,).\n",
    "        f (Callable[[Tensor], Tensor]): Activation function.\n",
    "        iters (int, optional): Number of iterations. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Tensor], Tensor]: A tuple containing\n",
    "            - a list of weight matrices modified by x_0 and c_i\n",
    "            - the initial vector x_0\n",
    "    \"\"\"\n",
    "    #this taylor series approximates W @ f(x+b)\n",
    "\n",
    "    m, n = W.size()\n",
    "    results: List[Tensor] = []\n",
    "\n",
    "    # Placeholder logic for demonstration\n",
    "    x0 = torch.rand((n), requires_grad=True)  # or some initialization, apparently b is supposed to be used here?\n",
    "\n",
    "    tensors:torch.Tensor = []\n",
    "\n",
    "    activated_gradient_iterative = f(x0)\n",
    "\n",
    "    # calculate \\theta_i_0 = W_i âŠ™ f^0(x0) / 0! + c[i]/n\n",
    "    matrix = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(m):\n",
    "      matrix.append(( ((W[i] * activated_gradient_iterative) / 1)+c[i]/n).detach() )\n",
    "    activated_gradient_iterative = torch.autograd.grad(activated_gradient_iterative, x0, grad_outputs=torch.ones_like(activated_gradient_iterative), create_graph=True)[0]\n",
    "\n",
    "    tensors.append(torch.stack(matrix,dim=0))\n",
    "\n",
    "\n",
    "    for k in range(1,iters):\n",
    "        matrix = []\n",
    "\n",
    "\n",
    "        for i in range(m):\n",
    "            matrix.append( ((W[i] * activated_gradient_iterative) / torch.exp(torch.lgamma(torch.tensor(k+1)))).detach() )\n",
    "        activated_gradient_iterative = torch.autograd.grad(activated_gradient_iterative, x0, grad_outputs=torch.ones_like(activated_gradient_iterative), create_graph=True)[0]\n",
    "\n",
    "        tensors.append(torch.stack(matrix,dim=0))\n",
    "\n",
    "\n",
    "    return torch.stack(tensors, dim=0), x0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rJIYtcEO0-0m"
   },
   "outputs": [],
   "source": [
    "m, n = (1,1)\n",
    "W = torch.rand((m,n))\n",
    "b = torch.rand((n))\n",
    "c = torch.rand((m))\n",
    "f = torch.nn.SiLU()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4z4AawAK15i-"
   },
   "outputs": [],
   "source": [
    "M, x0 = taylor_series_components(W,b,c,f,iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6BCRczFC174H"
   },
   "outputs": [],
   "source": [
    "\"\"\"def taylor_series_estimate(x:torch.Tensor,M:torch.Tensor,x0:torch.Tensor):\n",
    "\n",
    "  M (iters ,m ,n)\n",
    "  x0 (,n)\n",
    "  x (,n)\n",
    "\n",
    "\n",
    "\n",
    "  sum(for n,W in enumerate(M)\n",
    "    W @ (x-x0)**n)\"\"\"\n",
    "\n",
    "def taylor_series_estimate0(x: torch.Tensor, M: torch.Tensor, x0: torch.Tensor) -> torch.Tensor:\n",
    "  dx = x - x0                       # shape (n,)\n",
    "  powers = torch.stack([dx**n for n in range(M.shape[0])])  # shape (iters, n)\n",
    "  # batch matrix multiplication: (iters, m, n) @ (iters, n, 1) -> (iters, m, 1)\n",
    "  terms = torch.bmm(M, powers.unsqueeze(-1))  # (iters, m, 1)\n",
    "  return terms.sum(dim=0).squeeze(-1)         # (m,)\n",
    "\n",
    "def taylor_series_estimate_batched_einsum(x: torch.Tensor, M: torch.Tensor, x0: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Taylor series estimation using einsum for cleaner batched operations.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor, shape (batch_size, n) or (n,)\n",
    "        M: Coefficient matrices, shape (iters, m, n)\n",
    "        x0: Expansion point, shape (n,) or broadcastable to x\n",
    "    \n",
    "    Returns:\n",
    "        Estimated values, shape (batch_size, m) or (m,)\n",
    "    \"\"\"\n",
    "    # Ensure x is at least 2D for consistent handling\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(0)  # (1, n)\n",
    "        squeeze_output = True\n",
    "    else:\n",
    "        squeeze_output = False\n",
    "    \n",
    "    dx = x - x0  # shape (batch_size, n)\n",
    "    \n",
    "    # Compute powers: (batch_size, n) -> (iters, batch_size, n)\n",
    "    powers = torch.stack([dx**k for k in range(M.shape[0])])\n",
    "    \n",
    "    # Einstein summation: sum over iterations and n dimension\n",
    "    # 'imn,ibn->bm' means: (iters,m,n) * (iters,batch,n) -> (batch,m)\n",
    "    result = torch.einsum('imn,ibn->bm', M, powers)\n",
    "    \n",
    "    if squeeze_output:\n",
    "        result = result.squeeze(0)  # (m,)\n",
    "    \n",
    "    return result\n",
    "\n",
    "import torch\n",
    "\n",
    "def taylor_series_estimate2(x: torch.Tensor, M: torch.Tensor, x0: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Approximates a function using Taylor series expansion.\n",
    "\n",
    "    Args:\n",
    "        x:  Tensor of shape (..., n)\n",
    "        M:  Tensor of shape (iters, m, n) where each M[k] is the coefficient matrix for order k\n",
    "        x0: Tensor of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (..., m) representing the Taylor approximation.\n",
    "    \"\"\"\n",
    "    dx = x - x0\n",
    "    result = torch.zeros(M.shape[1], device=x.device, dtype=x.dtype)\n",
    "\n",
    "    # Use enumerate over M for matrix multiplications\n",
    "    for n, W in enumerate(M):\n",
    "        result = result + W @ (dx ** n)\n",
    "        #print(f\"Calculating W_{n} @ dx ** {n} = {W.item():.2f}@{dx.item() ** n:.2f}\")\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dYSaefP6OqN",
    "outputId": "5d618655-3611-498d-db6e-419f4d083ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0086], grad_fn=<SqueezeBackward1>) tensor([1.2247], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "x = x0\n",
    "x=torch.rand((n))\n",
    "a = taylor_series_estimate0(x, M[:7],x0)\n",
    "b = taylor_series_estimate_batched_einsum(x, M[:1],x0)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJ5cjHwrH-3F",
    "outputId": "386804ec-b6f5-4bbc-ea56-1058e254ecbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0086])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W @ f(x))+c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "sample_count = 5\n",
    "X = torch.rand((sample_count,n))\n",
    "y = taylor_series_estimate_batched_einsum(X, M,x0)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rDk7kkUZQrjA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: torch.Size([1, 1])\n",
      "b shape: torch.Size([1])\n",
      "Mean squared error: 0.000000\n",
      "\n",
      "A =\n",
      "tensor([[0.7732]], grad_fn=<SliceBackward0>)\n",
      "\n",
      "b = tensor([0.8172], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_with_bias = torch.cat([f(X), torch.ones(sample_count, 1)], dim=1)\n",
    "solution = torch.linalg.pinv(X_with_bias) @ y\n",
    "A = solution[:-1, :]  \n",
    "b = solution[-1, :]   \n",
    "\n",
    "print(f\"A shape: {A.shape}\")  # (n, m)\n",
    "print(f\"b shape: {b.shape}\")  # (m,)\n",
    "\n",
    "# Verify the fit\n",
    "y_pred = f(X) @ A + b\n",
    "mse = torch.mean((y - y_pred)**2)\n",
    "print(f\"Mean squared error: {mse.item():.6f}\")\n",
    "\n",
    "print(f\"\\nA =\\n{A}\")\n",
    "print(f\"\\nb = {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "l4NkcsmhP_LH",
    "outputId": "00dabedb-30f4-4486-db6e-4777a55ede47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8172])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linalg.svd: The input tensor A must have at least 2 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# SVD\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[0;32m----> 4\u001b[0m U, S, V \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(S\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot singular values\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linalg.svd: The input tensor A must have at least 2 dimensions."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# SVD\n",
    "print(c)\n",
    "\n",
    "U, S, V = torch.linalg.svd(c)\n",
    "\n",
    "print(S.shape)\n",
    "\n",
    "# Plot singular values\n",
    "plt.figure()\n",
    "plt.plot(S.numpy(), marker=\"o\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Singular Value\")\n",
    "plt.title(\"Singular Values of c\")\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "fQ8rf2PDI6o5",
    "outputId": "ebf2f8f1-d732-4806-da82-f2ace64c1927"
   },
   "outputs": [],
   "source": [
    "d_in, d_out = 10,100\n",
    "samples = 1000\n",
    "\n",
    "x = torch.rand(d_out,d_in)#10,100\n",
    "c_vec = torch.rand((d_out))\n",
    "\n",
    "samples_list = []\n",
    "for i in range(samples):\n",
    "  samples_list.append(x@torch.rand((d_in)))\n",
    "\n",
    "samples_list = torch.stack(samples_list)\n",
    "c = torch.stack([c_vec]*samples)\n",
    "\n",
    "W_plus_c = samples_list + c\n",
    "\n",
    "# SVD\n",
    "U, S, V = torch.linalg.svd(W_plus_c)\n",
    "\n",
    "print(S.shape)\n",
    "\n",
    "# Plot singular values\n",
    "plt.figure()\n",
    "plt.plot(S.numpy(), marker=\"o\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Singular Value\")\n",
    "plt.title(\"Singular Values of W_plus_c\")\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Solve least squares: (X^T X)^(-1) X^T y\n",
    "# X_with_bias: (sample_count, n+1)\n",
    "# y: (sample_count, m)\n",
    "# Solution will be shape (n+1, m)\n",
    "\n",
    "# Extract A and b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.repeat(2,1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0679, 0.7327, 0.0394, 0.5948, 0.7531],\n",
       "         [0.1648, 0.0825, 0.8914, 0.7887, 0.5388]],\n",
       "\n",
       "        [[0.0679, 0.7327, 0.0394, 0.5948, 0.7531],\n",
       "         [0.1648, 0.0825, 0.8914, 0.7887, 0.5388]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.view(2, -1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0679, 0.7327, 0.0394, 0.5948, 0.7531, 0.1648, 0.0825, 0.8914,\n",
       "          0.7887, 0.5388]],\n",
       "\n",
       "        [[0.0679, 0.7327, 0.0394, 0.5948, 0.7531, 0.1648, 0.0825, 0.8914,\n",
       "          0.7887, 0.5388]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.view(2, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
